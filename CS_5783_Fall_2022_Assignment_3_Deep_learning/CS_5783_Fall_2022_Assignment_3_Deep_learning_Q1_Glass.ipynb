{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPY0cYhdEcHUyQEZW2vOETy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salmanromeo/CS_5783_Machine_Learning_Fall_2022/blob/main/CS_5783_Fall_2022_Assignment_3_Deep_learning/CS_5783_Fall_2022_Assignment_3_Deep_learning_Q1_Glass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1**"
      ],
      "metadata": {
        "id": "FvZL5B71lHCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Design a convolutional neural network in Keras of at least 10 convolutional layers. Use the MNIST dataset for evaluation. You must try three designs as detailed below and provide your observations on the performance of each:\n",
        "1.   A regular CNN where the number of filters in each layer increases as the depth of the \n",
        "network grows i.e., the Lth layer will have more filters than the (L-1)th layer.\n",
        "2.   An inverted CNN where the number of filters in each layer decreases as the depth of the network grows i.e., the Lth layer will have less filters than the (L-1)th layer.\n",
        "1.   An hour-glass shaped CNN where the number of filters will increase till the Lth layer and reduce afterwards.\n",
        "\n",
        "#####Your goal is to design these networks and optimize them to their best performance by choosing the right hyperparameters for each network, such as the learning rate, batch size and the choice of optimizer (‘SGD’, ‘adam’, ‘RMSProp’). You must provide a detailed report of what values you tried for each hyperparameters, your observations on why the network performed well (or not) and the final accuracy for each network on the MNIST dataset.\n",
        "\n",
        "#####You can refer to the Keras documentation for more details.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AAQkJblMlSAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution 1**"
      ],
      "metadata": {
        "id": "HU_fpCECl0Ot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "3_r9qdntotR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "r6NFejZhlzaJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Data**"
      ],
      "metadata": {
        "id": "UL9SKcnuo5t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0 \n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "print(train_images.shape)\n",
        "\n",
        "# Add an additional dimension to represent the single-channel\n",
        "x_train = train_images.reshape(-1, 28, 28, 1)\n",
        "x_test = test_images.reshape(-1, 28, 28, 1)\n",
        "x_train = train_images.reshape(-1, 28, 28, 1)\n",
        "x_test = test_images.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9iD2d92o8Uq",
        "outputId": "618816f4-d31a-430f-8f3a-95e0c2d0f221"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting**"
      ],
      "metadata": {
        "id": "jQMTE8eVpCwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "fig, ax = plt.subplots(2,5,figsize = (20, 10))\n",
        "fig.suptitle('Train Images')\n",
        "ax = ax.flatten()\n",
        "for i in range(10):\n",
        "    im_idx = np.argwhere(train_labels == i)[0]\n",
        "    ax[i].set(xlabel='x', ylabel='y')\n",
        "    plt.setp(ax, xticks=[0, 27], yticks=[0, 27])\n",
        "    plottable_image = np.reshape(train_images[im_idx], (28, 28))\n",
        "    ax[i].imshow(plottable_image, cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "YGhOZq_OpFMH",
        "outputId": "2463b600-fc29-49ae-c831-262fe57d0529"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Hour-glass shaped CNN**"
      ],
      "metadata": {
        "id": "RTjJevDJqzdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model_g = tf.keras.models.Sequential()\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "\n",
        "cnn_model_g.add(tf.keras.layers.Flatten())\n",
        "cnn_model_g.add(tf.keras.layers.Dense(512))\n",
        "cnn_model_g.add(tf.keras.layers.Activation('relu'))\n",
        "cnn_model_g.add(tf.keras.layers.Dense(10))\n",
        "cnn_model_g.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "cnn_model_g.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "cnn_model_g.build(input_shape=(1,28,28,1))\n",
        "cnn_model_g.summary()\n",
        "\n",
        "model_cnn_g = cnn_model_g\n",
        "history_cnn_g = model_cnn_g.fit(x_train, train_labels, validation_split = 0.2, batch_size=512, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcHbCrmXrRKg",
        "outputId": "206a87b9-f858-4f65-8710-b863328a833e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (1, 28, 28, 64)           640       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (1, 14, 14, 64)           36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (1, 7, 7, 64)            0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (1, 7, 7, 128)            73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (1, 4, 4, 128)            147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (1, 2, 2, 128)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (1, 2, 2, 256)            295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (1, 1, 1, 256)            590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (1, 1, 1, 256)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (1, 1, 1, 128)            295040    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (1, 1, 1, 128)            147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (1, 1, 1, 128)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (1, 1, 1, 64)             73792     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (1, 1, 1, 64)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (1, 1, 1, 64)             36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (1, 64)                   0         \n",
            "                                                                 \n",
            " dense (Dense)               (1, 512)                  33280     \n",
            "                                                                 \n",
            " activation (Activation)     (1, 512)                  0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, 10)                   5130      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,736,010\n",
            "Trainable params: 1,736,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "94/94 [==============================] - 16s 62ms/step - loss: 1.5811 - accuracy: 0.4030 - val_loss: 0.6187 - val_accuracy: 0.7862\n",
            "Epoch 2/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.3292 - accuracy: 0.8989 - val_loss: 0.1609 - val_accuracy: 0.9517\n",
            "Epoch 3/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.1383 - accuracy: 0.9603 - val_loss: 0.1106 - val_accuracy: 0.9672\n",
            "Epoch 4/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.0903 - accuracy: 0.9740 - val_loss: 0.0806 - val_accuracy: 0.9770\n",
            "Epoch 5/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.0665 - accuracy: 0.9809 - val_loss: 0.0722 - val_accuracy: 0.9786\n",
            "Epoch 6/25\n",
            "94/94 [==============================] - 5s 48ms/step - loss: 0.0530 - accuracy: 0.9846 - val_loss: 0.0782 - val_accuracy: 0.9773\n",
            "Epoch 7/25\n",
            "94/94 [==============================] - 5s 53ms/step - loss: 0.0447 - accuracy: 0.9868 - val_loss: 0.0804 - val_accuracy: 0.9772\n",
            "Epoch 8/25\n",
            "94/94 [==============================] - 4s 46ms/step - loss: 0.0372 - accuracy: 0.9891 - val_loss: 0.0669 - val_accuracy: 0.9817\n",
            "Epoch 9/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.0301 - accuracy: 0.9913 - val_loss: 0.0543 - val_accuracy: 0.9858\n",
            "Epoch 10/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0606 - val_accuracy: 0.9839\n",
            "Epoch 11/25\n",
            "94/94 [==============================] - 4s 48ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.0474 - val_accuracy: 0.9878\n",
            "Epoch 12/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0603 - val_accuracy: 0.9862\n",
            "Epoch 13/25\n",
            "94/94 [==============================] - 4s 47ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0540 - val_accuracy: 0.9867\n",
            "Epoch 14/25\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0614 - val_accuracy: 0.9852\n",
            "Epoch 15/25\n",
            "94/94 [==============================] - 4s 45ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0581 - val_accuracy: 0.9871\n",
            "Epoch 16/25\n",
            "94/94 [==============================] - 4s 45ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
            "Epoch 17/25\n",
            "94/94 [==============================] - 5s 49ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0601 - val_accuracy: 0.9872\n",
            "Epoch 18/25\n",
            "94/94 [==============================] - 5s 51ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0578 - val_accuracy: 0.9873\n",
            "Epoch 19/25\n",
            "94/94 [==============================] - 5s 52ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.0512 - val_accuracy: 0.9883\n",
            "Epoch 20/25\n",
            "94/94 [==============================] - 4s 47ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0578 - val_accuracy: 0.9871\n",
            "Epoch 21/25\n",
            "94/94 [==============================] - 5s 51ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0535 - val_accuracy: 0.9878\n",
            "Epoch 22/25\n",
            "94/94 [==============================] - 5s 54ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0514 - val_accuracy: 0.9880\n",
            "Epoch 23/25\n",
            "94/94 [==============================] - 5s 54ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0550 - val_accuracy: 0.9888\n",
            "Epoch 24/25\n",
            "94/94 [==============================] - 5s 52ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.0545 - val_accuracy: 0.9886\n",
            "Epoch 25/25\n",
            "94/94 [==============================] - 5s 53ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.0545 - val_accuracy: 0.9888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_cnn_g.history['accuracy'])\n",
        "plt.plot(history_cnn_g.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "41vzITadtgU7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ff5f20a9-0414-4d72-b571-9bedc66c1d9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model_cnn_g.evaluate(x_train, train_labels)\n",
        "print('Train loss:', score[0])\n",
        "print('Train accuracy:', score[1])"
      ],
      "metadata": {
        "id": "7FA4JKBJtXZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41cb92e1-9354-4252-907f-2a7f1bdd8348"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0169 - accuracy: 0.9958\n",
            "Train loss: 0.016877416521310806\n",
            "Train accuracy: 0.9958166480064392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model_cnn_g.evaluate(x_test, test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "enaKfNlVtSwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2ce226-b6f7-4b2f-feea-3025540d53de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0427 - accuracy: 0.9890\n",
            "Test loss: 0.042658720165491104\n",
            "Test accuracy: 0.9890000224113464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Effect of learning rate on Hour-glass shaped CNN**"
      ],
      "metadata": {
        "id": "EA7e8chX74P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learningRate=[0.0001, 0.001, 0.01]\n",
        "acc=np.zeros(3)\n",
        "for i in range(len(learningRate)):\n",
        "  cnn_model_g = tf.keras.models.Sequential()\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "\n",
        "  cnn_model_g.add(tf.keras.layers.Flatten())\n",
        "  cnn_model_g.add(tf.keras.layers.Dense(512))\n",
        "  cnn_model_g.add(tf.keras.layers.Activation('relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Dense(10))\n",
        "  cnn_model_g.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "  cnn_model_g.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  cnn_model_g.build(input_shape=(1,28,28,1))\n",
        "  accuracy= cnn_model_g.fit(train_images, train_labels, batch_size=512, epochs=25)\n",
        "  acc[i]=accuracy.history['accuracy'][24]\n",
        "  cnn_model_g.summary()"
      ],
      "metadata": {
        "id": "9jr2GhC-3vNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c0bb34-90d7-4dbf-a202-d19f226d42a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "118/118 [==============================] - 6s 46ms/step - loss: 1.6087 - accuracy: 0.3632\n",
            "Epoch 2/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.4740 - accuracy: 0.8287\n",
            "Epoch 3/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.1316 - accuracy: 0.9611\n",
            "Epoch 4/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0807 - accuracy: 0.9770\n",
            "Epoch 5/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0586 - accuracy: 0.9832\n",
            "Epoch 6/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0505 - accuracy: 0.9855\n",
            "Epoch 7/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0386 - accuracy: 0.9888\n",
            "Epoch 8/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0324 - accuracy: 0.9910\n",
            "Epoch 9/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0254 - accuracy: 0.9930\n",
            "Epoch 10/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0227 - accuracy: 0.9938\n",
            "Epoch 11/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0217 - accuracy: 0.9937\n",
            "Epoch 12/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0181 - accuracy: 0.9949\n",
            "Epoch 13/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0155 - accuracy: 0.9956\n",
            "Epoch 14/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0145 - accuracy: 0.9958\n",
            "Epoch 15/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0115 - accuracy: 0.9966\n",
            "Epoch 16/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0116 - accuracy: 0.9967\n",
            "Epoch 17/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0151 - accuracy: 0.9958\n",
            "Epoch 18/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0131 - accuracy: 0.9963\n",
            "Epoch 19/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0131 - accuracy: 0.9961\n",
            "Epoch 20/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0057 - accuracy: 0.9984\n",
            "Epoch 21/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0076 - accuracy: 0.9977\n",
            "Epoch 22/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0088 - accuracy: 0.9975\n",
            "Epoch 23/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0081 - accuracy: 0.9980\n",
            "Epoch 24/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0041 - accuracy: 0.9988\n",
            "Epoch 25/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0094 - accuracy: 0.9974\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_50 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 1, 1, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 1, 1, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 1, 1, 128)         295040    \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 1, 1, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 1, 1, 64)          36928     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               33280     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,736,010\n",
            "Trainable params: 1,736,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "118/118 [==============================] - 6s 42ms/step - loss: 1.5927 - accuracy: 0.3669\n",
            "Epoch 2/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.3792 - accuracy: 0.8799\n",
            "Epoch 3/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.1440 - accuracy: 0.9629\n",
            "Epoch 4/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0937 - accuracy: 0.9758\n",
            "Epoch 5/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0644 - accuracy: 0.9836\n",
            "Epoch 6/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0985 - accuracy: 0.9718\n",
            "Epoch 7/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0401 - accuracy: 0.9895\n",
            "Epoch 8/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0326 - accuracy: 0.9915\n",
            "Epoch 9/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0237 - accuracy: 0.9935\n",
            "Epoch 10/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0175 - accuracy: 0.9954\n",
            "Epoch 11/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0163 - accuracy: 0.9955\n",
            "Epoch 12/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0156 - accuracy: 0.9958\n",
            "Epoch 13/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0162 - accuracy: 0.9957\n",
            "Epoch 14/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0125 - accuracy: 0.9966\n",
            "Epoch 15/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0150 - accuracy: 0.9958\n",
            "Epoch 16/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0099 - accuracy: 0.9974\n",
            "Epoch 17/25\n",
            "118/118 [==============================] - 5s 42ms/step - loss: 0.0099 - accuracy: 0.9973\n",
            "Epoch 18/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0109 - accuracy: 0.9969\n",
            "Epoch 19/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0127 - accuracy: 0.9966\n",
            "Epoch 20/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0089 - accuracy: 0.9977\n",
            "Epoch 21/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0084 - accuracy: 0.9978\n",
            "Epoch 22/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0074 - accuracy: 0.9979\n",
            "Epoch 23/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0046 - accuracy: 0.9987\n",
            "Epoch 24/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0060 - accuracy: 0.9984\n",
            "Epoch 25/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0105 - accuracy: 0.9973\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 1, 1, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 1, 1, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 1, 1, 128)         295040    \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 1, 1, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 1, 1, 64)          36928     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               33280     \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,736,010\n",
            "Trainable params: 1,736,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "118/118 [==============================] - 6s 44ms/step - loss: 1.7134 - accuracy: 0.3315\n",
            "Epoch 2/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.4455 - accuracy: 0.8565\n",
            "Epoch 3/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.1419 - accuracy: 0.9620\n",
            "Epoch 4/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0833 - accuracy: 0.9785\n",
            "Epoch 5/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0559 - accuracy: 0.9856\n",
            "Epoch 6/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0479 - accuracy: 0.9874\n",
            "Epoch 7/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0349 - accuracy: 0.9907\n",
            "Epoch 8/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0274 - accuracy: 0.9920\n",
            "Epoch 9/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0243 - accuracy: 0.9931\n",
            "Epoch 10/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0206 - accuracy: 0.9944\n",
            "Epoch 11/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0148 - accuracy: 0.9957\n",
            "Epoch 12/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0146 - accuracy: 0.9957\n",
            "Epoch 13/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0162 - accuracy: 0.9955\n",
            "Epoch 14/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0167 - accuracy: 0.9957\n",
            "Epoch 15/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0148 - accuracy: 0.9962\n",
            "Epoch 16/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0128 - accuracy: 0.9969\n",
            "Epoch 17/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0114 - accuracy: 0.9967\n",
            "Epoch 18/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0124 - accuracy: 0.9965\n",
            "Epoch 19/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0092 - accuracy: 0.9974\n",
            "Epoch 20/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0107 - accuracy: 0.9970\n",
            "Epoch 21/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0075 - accuracy: 0.9980\n",
            "Epoch 22/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0086 - accuracy: 0.9976\n",
            "Epoch 23/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0076 - accuracy: 0.9980\n",
            "Epoch 24/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0106 - accuracy: 0.9972\n",
            "Epoch 25/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0087 - accuracy: 0.9975\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_70 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 1, 1, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (None, 1, 1, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 1, 1, 128)         295040    \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_78 (Conv2D)          (None, 1, 1, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 1, 1, 64)          36928     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               33280     \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,736,010\n",
            "Trainable params: 1,736,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)\n",
        "plt.plot(np.array(learningRate).reshape(3,1), np.array(acc).reshape(3,1), color = 'red')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('learning rate')\n",
        "plt.title('Accuracy Vs Learning rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MybdQiN25amm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "4393ef86-1a48-410a-db70-2aa2e0493016"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99736667 0.99731666 0.99753332]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which one performed best**"
      ],
      "metadata": {
        "id": "hHuGwEUYnRYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "mydata = [[0.0001, 0.99736667],\n",
        "          [0.001, 0.99731666],\n",
        "          [0.01, 0.99753332]]\n",
        "head = [\"Learning Rate\", \"Accuarcy\"]\n",
        "# Display Table\n",
        "print(tabulate(mydata, headers=head, tablefmt=\"grid\", numalign=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Pq4sDSnSIq",
        "outputId": "1dfd2890-d761-4365-ac6e-a4b61ee8c296"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+\n",
            "|  Learning Rate  |  Accuarcy  |\n",
            "+=================+============+\n",
            "|     0.0001      |  0.997883  |\n",
            "+-----------------+------------+\n",
            "|      0.001      |  0.997933  |\n",
            "+-----------------+------------+\n",
            "|      0.01       |  0.997233  |\n",
            "+-----------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Based on the above results, we can say that for my case, learning rate = 0.01 gives highest accuarcy (0.99753332), but the other learning rate also shows good accuracy."
      ],
      "metadata": {
        "id": "n3-lNp7TthgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Effect of batch size on Hour-glass shaped CNN**"
      ],
      "metadata": {
        "id": "-nLHBAdNnWpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch=[128, 256, 512]\n",
        "acc=np.zeros(3)\n",
        "for i in range(len(batch)):\n",
        "  cnn_model_g = tf.keras.models.Sequential()\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "  cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "\n",
        "  cnn_model_g.add(tf.keras.layers.Flatten())\n",
        "  cnn_model_g.add(tf.keras.layers.Dense(512))\n",
        "  cnn_model_g.add(tf.keras.layers.Activation('relu'))\n",
        "  cnn_model_g.add(tf.keras.layers.Dense(10))\n",
        "  cnn_model_g.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "  cnn_model_g.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  cnn_model_g.build(input_shape=(1,28,28,1))\n",
        "  accuracy= cnn_model_g.fit(train_images, train_labels, batch_size=batch[i], epochs=25)\n",
        "  acc[i]=accuracy.history['accuracy'][24]\n",
        "  cnn_model_g.summary()"
      ],
      "metadata": {
        "id": "LIF_Haxn54ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b93b4d2-7e85-43f9-b289-42b057b5ec38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "469/469 [==============================] - 11s 19ms/step - loss: 0.7936 - accuracy: 0.7010\n",
            "Epoch 2/25\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.1143 - accuracy: 0.9716\n",
            "Epoch 3/25\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0655 - accuracy: 0.9839\n",
            "Epoch 4/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0531 - accuracy: 0.9868\n",
            "Epoch 5/25\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0427 - accuracy: 0.9890\n",
            "Epoch 6/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0328 - accuracy: 0.9917\n",
            "Epoch 7/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0318 - accuracy: 0.9918\n",
            "Epoch 8/25\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0267 - accuracy: 0.9936\n",
            "Epoch 9/25\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0252 - accuracy: 0.9941\n",
            "Epoch 10/25\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0207 - accuracy: 0.9950\n",
            "Epoch 11/25\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0202 - accuracy: 0.9954\n",
            "Epoch 12/25\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.0179 - accuracy: 0.9955\n",
            "Epoch 13/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0176 - accuracy: 0.9962\n",
            "Epoch 14/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0155 - accuracy: 0.9963\n",
            "Epoch 15/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0217 - accuracy: 0.9949\n",
            "Epoch 16/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0140 - accuracy: 0.9969\n",
            "Epoch 17/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0164 - accuracy: 0.9964\n",
            "Epoch 18/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0085 - accuracy: 0.9980\n",
            "Epoch 19/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0113 - accuracy: 0.9973\n",
            "Epoch 20/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0126 - accuracy: 0.9972\n",
            "Epoch 21/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0117 - accuracy: 0.9972\n",
            "Epoch 22/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0145 - accuracy: 0.9966\n",
            "Epoch 23/25\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.0062 - accuracy: 0.9986\n",
            "Epoch 24/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0062 - accuracy: 0.9986\n",
            "Epoch 25/25\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0096 - accuracy: 0.9977\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_80 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_82 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_84 (Conv2D)          (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 1, 1, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 1, 1, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 1, 1, 128)         295040    \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 1, 1, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_89 (Conv2D)          (None, 1, 1, 64)          36928     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               33280     \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,736,010\n",
            "Trainable params: 1,736,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "235/235 [==============================] - 7s 24ms/step - loss: 1.2134 - accuracy: 0.5366\n",
            "Epoch 2/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1799 - accuracy: 0.9576\n",
            "Epoch 3/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0887 - accuracy: 0.9776\n",
            "Epoch 4/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0624 - accuracy: 0.9841\n",
            "Epoch 5/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0414 - accuracy: 0.9897\n",
            "Epoch 6/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0357 - accuracy: 0.9910\n",
            "Epoch 7/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0285 - accuracy: 0.9928\n",
            "Epoch 8/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0229 - accuracy: 0.9935\n",
            "Epoch 9/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0227 - accuracy: 0.9945\n",
            "Epoch 10/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0228 - accuracy: 0.9944\n",
            "Epoch 11/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0196 - accuracy: 0.9949\n",
            "Epoch 12/25\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0146 - accuracy: 0.9962\n",
            "Epoch 13/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0140 - accuracy: 0.9965\n",
            "Epoch 14/25\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0114 - accuracy: 0.9970\n",
            "Epoch 15/25\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0156 - accuracy: 0.9962\n",
            "Epoch 16/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0117 - accuracy: 0.9970\n",
            "Epoch 17/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0102 - accuracy: 0.9974\n",
            "Epoch 18/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0119 - accuracy: 0.9971\n",
            "Epoch 19/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0112 - accuracy: 0.9974\n",
            "Epoch 20/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0104 - accuracy: 0.9977\n",
            "Epoch 21/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0091 - accuracy: 0.9979\n",
            "Epoch 22/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0110 - accuracy: 0.9971\n",
            "Epoch 23/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0109 - accuracy: 0.9973\n",
            "Epoch 24/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0065 - accuracy: 0.9984\n",
            "Epoch 25/25\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0089 - accuracy: 0.9982\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_90 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_92 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_93 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 1, 1, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 1, 1, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 1, 1, 128)         295040    \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_48 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 1, 1, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_49 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 1, 1, 64)          36928     \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               33280     \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,736,010\n",
            "Trainable params: 1,736,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "118/118 [==============================] - 6s 44ms/step - loss: 1.7073 - accuracy: 0.3294\n",
            "Epoch 2/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.3433 - accuracy: 0.8873\n",
            "Epoch 3/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.1189 - accuracy: 0.9656\n",
            "Epoch 4/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0775 - accuracy: 0.9772\n",
            "Epoch 5/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0558 - accuracy: 0.9844\n",
            "Epoch 6/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0415 - accuracy: 0.9884\n",
            "Epoch 7/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0342 - accuracy: 0.9903\n",
            "Epoch 8/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0325 - accuracy: 0.9906\n",
            "Epoch 9/25\n",
            "118/118 [==============================] - 5s 45ms/step - loss: 0.0265 - accuracy: 0.9923\n",
            "Epoch 10/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0217 - accuracy: 0.9937\n",
            "Epoch 11/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0191 - accuracy: 0.9944\n",
            "Epoch 12/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0185 - accuracy: 0.9951\n",
            "Epoch 13/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0140 - accuracy: 0.9960\n",
            "Epoch 14/25\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0132 - accuracy: 0.9963\n",
            "Epoch 15/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0132 - accuracy: 0.9961\n",
            "Epoch 16/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0139 - accuracy: 0.9957\n",
            "Epoch 17/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0126 - accuracy: 0.9965\n",
            "Epoch 18/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0081 - accuracy: 0.9979\n",
            "Epoch 19/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0106 - accuracy: 0.9971\n",
            "Epoch 20/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0091 - accuracy: 0.9973\n",
            "Epoch 21/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0081 - accuracy: 0.9979\n",
            "Epoch 22/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0067 - accuracy: 0.9982\n",
            "Epoch 23/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0085 - accuracy: 0.9980\n",
            "Epoch 24/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0117 - accuracy: 0.9970\n",
            "Epoch 25/25\n",
            "118/118 [==============================] - 5s 43ms/step - loss: 0.0068 - accuracy: 0.9982\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_100 (Conv2D)         (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_104 (Conv2D)         (None, 2, 2, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 1, 1, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 1, 1, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 1, 1, 128)         295040    \n",
            "                                                                 \n",
            " conv2d_107 (Conv2D)         (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_53 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_108 (Conv2D)         (None, 1, 1, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 1, 1, 64)          36928     \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               33280     \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,736,010\n",
            "Trainable params: 1,736,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)\n",
        "plt.plot(np.array(batch).reshape(3,1), np.array(acc).reshape(3,1), color = 'red')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Batch size')\n",
        "plt.title('Accuracy Vs Batch size')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "uGhMN4ueoqjX",
        "outputId": "4df81feb-c560-42e6-c1c2-61792525db33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99771667 0.99816668 0.99818331]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which one performed best**"
      ],
      "metadata": {
        "id": "AYdYhY9OorBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "mydata = [[128, 0.99771667],\n",
        "          [256, 0.99816668],\n",
        "          [512, 0.99818331]]\n",
        "head = [\"Batch Size\", \"Accuarcy\"]\n",
        "# Display Table\n",
        "print(tabulate(mydata, headers=head, tablefmt=\"grid\", numalign=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNJrTBlCotAa",
        "outputId": "a24e0513-15fb-4881-df56-1536bad43503"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------+\n",
            "|  Batch Size  |  Accuarcy  |\n",
            "+==============+============+\n",
            "|     128      |  0.997717  |\n",
            "+--------------+------------+\n",
            "|     256      |  0.998167  |\n",
            "+--------------+------------+\n",
            "|     512      |  0.998183  |\n",
            "+--------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Based on the above results, we can say that for my case, batch = 512 gives highest accuarcy (0.998183)."
      ],
      "metadata": {
        "id": "6p0gIH1Yz0ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Effect of optimizer on Hour-glass shaped CNN**"
      ],
      "metadata": {
        "id": "FL8Q9KUWoxIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch=[512]\n",
        "acc1=np.zeros(1)\n",
        "acc2=np.zeros(1)\n",
        "acc3=np.zeros(1)\n",
        "for k in range(3):\n",
        "  for i in range(len(batch)):    \n",
        "        cnn_model_g = tf.keras.models.Sequential()\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2),padding='same'))\n",
        "        cnn_model_g.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "\n",
        "        cnn_model_g.add(tf.keras.layers.Flatten())\n",
        "        cnn_model_g.add(tf.keras.layers.Dense(512))\n",
        "        cnn_model_g.add(tf.keras.layers.Activation('relu'))\n",
        "        cnn_model_g.add(tf.keras.layers.Dense(10))\n",
        "        cnn_model_g.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "        if k==0:\n",
        "          opt_lr = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "          cnn_model_g.compile(loss='sparse_categorical_crossentropy', optimizer=opt_lr, metrics=['accuracy'])\n",
        "          cnn_model_g.build(input_shape=(1,28,28,1)) \n",
        "          accuracy1= cnn_model_g.fit(train_images, train_labels, batch_size=batch[i], epochs=25, verbose=0)\n",
        "          acc1[i]=accuracy1.history['accuracy'][24]\n",
        "        elif k==1:\n",
        "          opt_lr = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "          cnn_model_g.compile(loss='sparse_categorical_crossentropy', optimizer=opt_lr, metrics=['accuracy'])\n",
        "          cnn_model_g.build(input_shape=(1,28,28,1))\n",
        "          accuracy2= cnn_model_g.fit(train_images, train_labels, batch_size=batch[i], epochs=25, verbose=0)\n",
        "          acc2[i]=accuracy2.history['accuracy'][24]\n",
        "        else:\n",
        "          opt_lr = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "          cnn_model_g.compile(loss='sparse_categorical_crossentropy', optimizer=opt_lr, metrics=['accuracy'])\n",
        "          cnn_model_g.build(input_shape=(1,28,28,1))\n",
        "          accuracy3= cnn_model_g.fit(train_images, train_labels, batch_size=batch[i], epochs=25, verbose=0)\n",
        "          acc3[i]=accuracy3.history['accuracy'][24]"
      ],
      "metadata": {
        "id": "GLWWcCeqoz6L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc1)\n",
        "print(acc2)\n",
        "print(acc3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nPPRF9-0Iao",
        "outputId": "6e7f7712-6cc7-4727-8dcb-d6f091bcf9b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99831665]\n",
            "[0.11236667]\n",
            "[0.99791664]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "mydata = [[0.99831665, 0.11236667, 0.99791664]]\n",
        "head = [\"Adam Accuracy\", \"SGD Accuracy\", \"RMSprop Accuracy\"]\n",
        "# Display Table\n",
        "print(tabulate(mydata, headers=head, tablefmt=\"grid\", numalign=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPuZcR0Y1IFz",
        "outputId": "cb7ffcdc-3950-489a-931d-538173a62cba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+--------------------+\n",
            "|  Adam Accuracy  |  SGD Accuracy  |  RMSprop Accuracy  |\n",
            "+=================+================+====================+\n",
            "|    0.998317     |    0.112367    |      0.997917      |\n",
            "+-----------------+----------------+--------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison**"
      ],
      "metadata": {
        "id": "JeNffrgo0M1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "mydata = [[\"Regular CNN\", 0.0310057420283556, 0.9918000102043152, 0.06496333330869675, 0.9848999977111816],\n",
        "          [\"Inverted\", 0.014482562430202961, 0.996666669845581, 0.04515833407640457, 0.9887999892234802],\n",
        "          [\"Hour-glass shaped CNN\", 0.016877416521310806, 0.9958166480064392, 0.042658720165491104, 0.9890000224113464]]\n",
        "head = [\"CNN\", \"Train loss\", \"Train accuracy\", \"Test accuracy\", \"Test accuracy\"]\n",
        "# Display Table\n",
        "print(tabulate(mydata, headers=head, tablefmt=\"grid\", numalign=\"center\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29jqmc6b1kSX",
        "outputId": "d0ef8470-bbd2-4059-9e1b-8b3de3c6c297"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+--------------+------------------+-----------------+-----------------+\n",
            "| CNN                   |  Train loss  |  Train accuracy  |  Test accuracy  |  Test accuracy  |\n",
            "+=======================+==============+==================+=================+=================+\n",
            "| Regular CNN           |  0.0310057   |      0.9918      |    0.0649633    |     0.9849      |\n",
            "+-----------------------+--------------+------------------+-----------------+-----------------+\n",
            "| Inverted              |  0.0144826   |     0.996667     |    0.0451583    |     0.9888      |\n",
            "+-----------------------+--------------+------------------+-----------------+-----------------+\n",
            "| Hour-glass shaped CNN |  0.0168774   |     0.995817     |    0.0426587    |      0.989      |\n",
            "+-----------------------+--------------+------------------+-----------------+-----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam and RMSprop otimizer gives better result instead of SGD. From all the tables, graphs and discussion, we can conclude that Adam optimizer with 0.001 learning rate and 512 batch size led to a proper accuracy with 25 epocs."
      ],
      "metadata": {
        "id": "clewCsqf0Whz"
      }
    }
  ]
}